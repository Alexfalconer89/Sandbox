{"job":{"components":{"196868":{"id":196868,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":96,"y":-48,"width":32,"height":32,"inputConnectorIDs":[196876],"outputSuccessConnectorIDs":[196887],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Update Initial Table"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"-- This update is to ensure we dont re-extract recs for other suppression checks once we have found a match\nupdate ${Database}.temp.nestle_aio_cleanse_out_to_read\nset deceased_flag = 'Y',\n    deceased_flag_source = 'Experian Mortality'\n--where name_urn in\nwhere new_ref in\n(\n\tselect \n      \ttrim(input_json:InputReference,'\"')\n\tfrom ${Database}.staging.read_api_expmort\n\twhere trim(input_json:MailSuppressionResultDeceasedFlag,'\"') = 'X' \n\t);\n"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"196872":{"id":196872,"inputCardinality":"ZERO","outputCardinality":"MANY","connectorHint":"UNCONDITIONAL","executionHint":"FLOW","implementationID":444132438,"x":-800,"y":-112,"width":32,"height":32,"inputConnectorIDs":[],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[196886],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Start 0"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"196873":{"id":196873,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-1773186960,"x":-96,"y":-48,"width":32,"height":32,"inputConnectorIDs":[196880],"outputSuccessConnectorIDs":[196876],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{"1":{"slot":1,"fromId":null,"fromName":"Completed At","mapTo":"Error_CompletedAt"},"2":{"slot":2,"fromId":null,"fromName":"Component","mapTo":"Error_Component"},"3":{"slot":3,"fromId":null,"fromName":"Duration","mapTo":"Error_Duration"},"4":{"slot":4,"fromId":null,"fromName":"Message","mapTo":"Error_Message"},"5":{"slot":5,"fromId":null,"fromName":"Row Count","mapTo":"Error_RowCount"},"6":{"slot":6,"fromId":null,"fromName":"Started At","mapTo":"Error_StartedAt"},"7":{"slot":7,"fromId":null,"fromName":"Status","mapTo":"Error_Status"}},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Move files"}}}},"visible":true},"2":{"slot":2,"name":"Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"###\n# Variables are directly accessible: \n#   print myvar\n# Updating a variable:\n#   context.updateVariable('myvar', 'new-value')\n# Grid Variables are accessible via the context:\n#   print context.getGridVariable('mygridvar')\n# Updating a grid variable:\n#   context.updateGridVariable('mygridvar', [['list','of'],['lists','!']])\n# A database cursor can be accessed from the context (Jython only):\n#   cursor = context.cursor()\n#   cursor.execute('select count(*) from mytable')\n#   rowcount = cursor.fetchone()[0]\n###\n\nfrom datetime import datetime\nimport time\nimport boto3\n\ns3 = boto3.resource('s3')\ns3BucketName = '${Bucket}'\nbaseFolderKey = \"data_in/${Database}_READ_API/\"\noldFolderKey = baseFolderKey + 'to_process'\nnewFolderKey = baseFolderKey + datetime.today().strftime('%Y%m%d')\n\nprint (baseFolderKey)\n\nbucket = s3.Bucket(s3BucketName)\nfor object in bucket.objects.filter(Prefix=oldFolderKey):\n\tsrcKey = object.key\n\tprint (srcKey)\n\tif not srcKey.endswith('/'):\n\t\tfileName = srcKey.split('/')[-1]\n\t\tdestFileKey = newFolderKey + '/' + fileName\n\t\tcopySource = s3BucketName + '/' + srcKey         \n\t\ts3.Object(s3BucketName, destFileKey).copy_from(CopySource=copySource)\n\t\ts3.Object('${Bucket}', srcKey).delete() "}}}},"visible":true},"3":{"slot":3,"name":"Interpreter","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Python 3"}}}},"visible":true},"4":{"slot":4,"name":"Timeout","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"INTEGER","value":"360"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"196874":{"id":196874,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":256,"y":-48,"width":32,"height":32,"inputConnectorIDs":[196887],"outputSuccessConnectorIDs":[],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Insert Suppressions to DB"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"-- Now insert the records to the supp_dead table for this source\ninsert into ${Database}.db.supps_dead\n   (\n        supp_urn,\n        data_date,\n        title,\n        firstname,\n        lastname,\n        company,\n        add1,\n        add2,\n        add3,\n        add4,\n        add5,\n        postcode,\n        country,\n        email,\n        source,\n        source_file,\n        source_urn,\n        source_date\n    ) \n        select \n        cast(cast(row_number() over(order by 1) as int) + nvl((select max(supp_urn) from ${Database}.db.supps_dead),0) as int),\n        current_date(),\n        coalesce(left(trim(title),30),''),\n        coalesce(left(trim(firstname),30),''),\n        coalesce(left(trim(lastname),30),''),\n        '',\n        coalesce(left(trim(add1),50),''),\n        coalesce(left(trim(add2),50),''),\n        coalesce(left(trim(add3),50),''),\n        coalesce(left(trim(add4),50),''),\n        coalesce(left(trim(add5),50),''),\n        coalesce(left(trim(postcode),14),''),\n       'UK',\n        '',\n       'SUPP_DEAD_3', -- should we change this to READ_API ?\n       'READ_API_EXPMORT_responses__'||to_varchar(current_date(), 'YYMMDD')||'_nnnnnn.json',  -- filename ??\n        LEFT(trim(name_urn), 50) as source_urn,\n        current_date()\n    from ${Database}.temp.nestle_aio_cleanse_out_to_read\n    where DECEASED_FLAG > ''\n    and DECEASED_FLAG_SOURCE = 'Experian Mortality';\n\n-- **** INSERT TO HCP TABLES IS DONE IN HCP BUILD BY IDENTIFYING MISSING RECORDS ****\n"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"196875":{"id":196875,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":-640,"y":-112,"width":32,"height":32,"inputConnectorIDs":[196886],"outputSuccessConnectorIDs":[196883],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{"1":{"slot":1,"fromId":null,"fromName":"Completed At","mapTo":"Error_CompletedAt"},"2":{"slot":2,"fromId":null,"fromName":"Component","mapTo":"Error_Component"},"3":{"slot":3,"fromId":null,"fromName":"Duration","mapTo":"Error_Duration"},"4":{"slot":4,"fromId":null,"fromName":"Message","mapTo":"Error_Message"},"5":{"slot":5,"fromId":null,"fromName":"Row Count","mapTo":"Error_RowCount"},"6":{"slot":6,"fromId":null,"fromName":"Started At","mapTo":"Error_StartedAt"},"7":{"slot":7,"fromId":null,"fromName":"Status","mapTo":"Error_Status"}},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Create table for EXPMORT cleaning"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"-- MAIN selections are run prior to this job before any API calls for Nestle\n                \n--\n--EXPERIAN MORTALITY PREP \ncreate or replace table ${Database}.temp.uk_changes_for_cleaning_expmort\nas\n--select to_char(name_urn) as \"Reference\" changed to numeric ref to allow modval version and chunking\nselect to_char(new_ref) as \"Reference\"\n    ,replace(trim(nvl(title,'')||' '||nvl(firstname,'')||' '||nvl(lastname,'')),'  ',' ') as \"FullName\"\n    ,add1 as \"AddressLine1\"\n    ,nvl(add2,'') as \"AddressLine2\"\n    ,nvl(add3,'') as \"AddressLine3\"\n    ,nvl(add4,'') as \"AddressLine4\"\n    ,nvl(add5,'') as \"AddressLine5\"\n    ,postcode\tas \"AddressLine6\"\n\t,'' as \"AddressLine7\"\nfrom ${Database}.temp.nestle_aio_cleanse_out_to_read\nwhere deceased_flag = '' \n-- this check is to ensure we dont re-extract people in later stages who have already been flagged earlier in this job\n;\n\n\n-- The following code just shuffles address lines along where blank address lines exist mid address to improve matches\nupdate ${Database}.temp.uk_changes_for_cleaning_expmort\nset \"AddressLine2\" = case when \"AddressLine3\" > '' then \"AddressLine3\"\n\t\t\t\t\t\twhen \"AddressLine4\" > '' then \"AddressLine4\"\n\t\t\t\t\t\twhen \"AddressLine5\" > '' then \"AddressLine5\"\n\t\t\t\t\t\twhen \"AddressLine6\" > '' then \"AddressLine6\"\n\t\t\t\t\t\twhen \"AddressLine7\" > '' then \"AddressLine7\"\n\t\t\t\t\t\telse ''\n\t\t\t\t\t\tend\n\t,\"AddressLine3\" = ''\n\t,\"AddressLine4\" = case when \"AddressLine3\" = '' then '' else \"AddressLine4\" end\n\t,\"AddressLine5\" = case when \"AddressLine3\" = '' and \"AddressLine4\" = '' then '' else \"AddressLine5\" end\n\t,\"AddressLine6\" = case when \"AddressLine3\" = '' and \"AddressLine4\" = ''  and \"AddressLine5\" = '' then '' else \"AddressLine6\" end\n\t,\"AddressLine7\" = case when \"AddressLine3\" = '' and \"AddressLine4\" = ''  and \"AddressLine5\" = '' and \"AddressLine6\" = ''then '' else \"AddressLine7\" end\nwhere \"AddressLine2\" = ''\n;\n\nupdate ${Database}.temp.uk_changes_for_cleaning_expmort\nset \"AddressLine3\" = case when \"AddressLine4\" > '' then \"AddressLine4\"\n\t\t\t\t\t\twhen \"AddressLine5\" > '' then \"AddressLine5\"\n\t\t\t\t\t\twhen \"AddressLine6\" > '' then \"AddressLine6\"\n\t\t\t\t\t\twhen \"AddressLine7\" > '' then \"AddressLine7\"\n\t\t\t\t\t\telse ''\n\t\t\t\t\t\tend\n\t,\"AddressLine4\" = ''\n\t,\"AddressLine5\" = case when \"AddressLine4\" = '' then '' else \"AddressLine5\" end\n\t,\"AddressLine6\" = case when \"AddressLine4\" = ''  and \"AddressLine5\" = '' then '' else \"AddressLine6\" end\n\t,\"AddressLine7\" = case when \"AddressLine4\" = ''  and \"AddressLine5\" = '' and \"AddressLine6\" = ''then '' else \"AddressLine7\" end\nwhere \"AddressLine3\" = ''\n;\n\nupdate ${Database}.temp.uk_changes_for_cleaning_expmort\nset \"AddressLine4\" = case when \"AddressLine5\" > '' then \"AddressLine5\"\n\t\t\t\t\t\twhen \"AddressLine6\" > '' then \"AddressLine6\"\n\t\t\t\t\t\twhen \"AddressLine7\" > '' then \"AddressLine7\"\n\t\t\t\t\t\telse ''\n\t\t\t\t\t\tend\n\t,\"AddressLine5\" = ''\n\t,\"AddressLine6\" = case when \"AddressLine5\" = '' then '' else \"AddressLine6\" end\n\t,\"AddressLine7\" = case when \"AddressLine5\" = '' and \"AddressLine6\" = ''then '' else \"AddressLine7\" end\nwhere \"AddressLine4\" = ''\n;\n\nupdate ${Database}.temp.uk_changes_for_cleaning_expmort\nset \"AddressLine5\" = case when \"AddressLine6\" > '' then \"AddressLine6\"\n\t\t\t\t\t\twhen \"AddressLine7\" > '' then \"AddressLine7\"\n\t\t\t\t\t\telse ''\n\t\t\t\t\t\tend\n\t,\"AddressLine6\" = ''\n\t,\"AddressLine7\" = case when \"AddressLine6\" = ''then '' else \"AddressLine7\" end\nwhere \"AddressLine5\" = ''\n;\n\nupdate ${Database}.temp.uk_changes_for_cleaning_expmort\nset \"AddressLine6\" = case when \"AddressLine7\" > '' then \"AddressLine7\"\n\t\t\t\t\t\telse ''\n\t\t\t\t\t\tend\n\t,\"AddressLine7\" = ''\nwhere \"AddressLine6\" = ''\n;"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"196877":{"id":196877,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-159239741,"x":-480,"y":-144,"width":32,"height":32,"inputConnectorIDs":[196883],"outputSuccessConnectorIDs":[196882],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{"1":{"slot":1,"fromId":null,"fromName":"Completed At","mapTo":"Error_CompletedAt"},"2":{"slot":2,"fromId":null,"fromName":"Component","mapTo":"Error_Component"},"3":{"slot":3,"fromId":null,"fromName":"Duration","mapTo":"Error_Duration"},"4":{"slot":4,"fromId":null,"fromName":"Message","mapTo":"Error_Message"},"5":{"slot":5,"fromId":null,"fromName":"Row Count","mapTo":"Error_RowCount"},"6":{"slot":6,"fromId":null,"fromName":"Started At","mapTo":"Error_StartedAt"},"7":{"slot":7,"fromId":null,"fromName":"Status","mapTo":"Error_Status"}},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Run API for Experian Mortality"}}}},"visible":true},"2":{"slot":2,"name":"Region","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"eu-west-1"}}}},"visible":true},"3":{"slot":3,"name":"Queue Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"${SQSClient}_expmort.fifo"}}}},"visible":true},"4":{"slot":4,"name":"Message","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"READ_API_EXPMORT_GO"}}}},"visible":true},"5":{"slot":5,"name":"Message Format","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Plain"}}}},"visible":true},"6":{"slot":6,"name":"Message Group Id","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"READ_API_EXPMORT_GO"}}}},"visible":true},"7":{"slot":7,"name":"Message Deduplication Id","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"${DateForQueue.now().format(\"yyyyMMddHHmmssSSS\")}"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"196878":{"id":196878,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-798585337,"x":-224,"y":-144,"width":32,"height":32,"inputConnectorIDs":[196881],"outputSuccessConnectorIDs":[196880],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{"1":{"slot":1,"fromId":null,"fromName":"Completed At","mapTo":"Error_CompletedAt"},"2":{"slot":2,"fromId":null,"fromName":"Component","mapTo":"Error_Component"},"3":{"slot":3,"fromId":null,"fromName":"Duration","mapTo":"Error_Duration"},"4":{"slot":4,"fromId":null,"fromName":"Message","mapTo":"Error_Message"},"5":{"slot":5,"fromId":null,"fromName":"Row Count","mapTo":"Error_RowCount"},"6":{"slot":6,"fromId":null,"fromName":"Started At","mapTo":"Error_StartedAt"},"7":{"slot":7,"fromId":null,"fromName":"Status","mapTo":"Error_Status"}},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Load EXPMORT file into staging"}}}},"visible":true},"2":{"slot":2,"name":"SQL Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"truncate table ${Database}.staging.read_api_expmort;\n\ncopy into ${Database}.staging.read_api_expmort\nfrom 's3://${Bucket}/data_in/${Database}_READ_API/to_process/' storage_integration = ${Database}_S3_SI\npattern = '.*READ_API_EXPMORT_0_responses.*'\nfile_format = (type='JSON' strip_outer_array = TRUE)\non_error = continue\nforce=true\n;\ncopy into ${Database}.staging.read_api_expmort\nfrom 's3://${Bucket}/data_in/${Database}_READ_API/to_process/' storage_integration = ${Database}_S3_SI\npattern = '.*READ_API_EXPMORT_1_responses.*'\nfile_format = (type='JSON' strip_outer_array = TRUE)\non_error = continue\nforce=true\n;\n\ntruncate table ${Database}.staging.suppressions_log_expmort;\n\ncopy into ${Database}.staging.suppressions_log_expmort\nfrom 's3://${Bucket}/data_in/${Database}_READ_API/to_process/' storage_integration = ${Database}_S3_SI\npattern = '.*READ_API_EXPMORT_0_supps_log.*'\nfile_format = (TYPE = CSV, ENCODING='UTF8',FIELD_DELIMITER = '\t')\non_error = continue\nforce=true\n;\ncopy into ${Database}.staging.suppressions_log_expmort\nfrom 's3://${Bucket}/data_in/${Database}_READ_API/to_process/' storage_integration = ${Database}_S3_SI\npattern = '.*READ_API_EXPMORT_1_supps_log.*'\nfile_format = (TYPE = CSV, ENCODING='UTF8',FIELD_DELIMITER = '\t')\non_error = continue\nforce=true\n;\n\ninsert into tbw.db.suppressions_log\nselect\n'${Database}'\n,suppression_type\n,current_date\n,sum(total)\nfrom ${Database}.staging.suppressions_log_expmort\ngroup by suppression_type\n;\n"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]},"196879":{"id":196879,"inputCardinality":"ONE","outputCardinality":"MANY","connectorHint":"SUCCESS_FAIL","executionHint":"EXECUTE","implementationID":-1773186960,"x":-352,"y":-48,"width":32,"height":32,"inputConnectorIDs":[196882],"outputSuccessConnectorIDs":[196881],"outputFailureConnectorIDs":[],"outputUnconditionalConnectorIDs":[],"outputTrueConnectorIDs":[],"outputFalseConnectorIDs":[],"exportMappings":{"1":{"slot":1,"fromId":null,"fromName":"Completed At","mapTo":"Error_CompletedAt"},"2":{"slot":2,"fromId":null,"fromName":"Component","mapTo":"Error_Component"},"3":{"slot":3,"fromId":null,"fromName":"Duration","mapTo":"Error_Duration"},"4":{"slot":4,"fromId":null,"fromName":"Message","mapTo":"Error_Message"},"5":{"slot":5,"fromId":null,"fromName":"Row Count","mapTo":"Error_RowCount"},"6":{"slot":6,"fromId":null,"fromName":"Started At","mapTo":"Error_StartedAt"},"7":{"slot":7,"fromId":null,"fromName":"Status","mapTo":"Error_Status"}},"parameters":{"1":{"slot":1,"name":"Name","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Wait for EXPMORT go file"}}}},"visible":true},"2":{"slot":2,"name":"Script","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"###\n# Variables are directly accessible: \n#   print myvar\n# Updating a variable:\n#   context.updateVariable('myvar', 'new-value')\n# Grid Variables are accessible via the context:\n#   print context.getGridVariable('mygridvar')\n# Updating a grid variable:\n#   context.updateGridVariable('mygridvar', [['list','of'],['lists','!']])\n# A database cursor can be accessed from the context (Jython only):\n#   cursor = context.cursor()\n#   cursor.execute('select count(*) from mytable')\n#   rowcount = cursor.fetchone()[0]\n###\n\nfrom datetime import datetime\nimport time\nimport boto3\n\ns3 = boto3.resource('s3')\n\n# we are running mod 2 for parcelforce so go files are _0 and _1 we need to wait till _1 is ready then all data processed\nfname0= \"data_in/\"+Database+\"_READ_API/to_process/read_api_EXPMORT_0.go\"\nfname1= \"data_in/\"+Database+\"_READ_API/to_process/read_api_EXPMORT_1.go\"\nprint(fname0)\nprint(fname1)\n\nwhile True:\n  try:\n      s3.Object('${Bucket}', fname0).load() \n  except:\n    time.sleep(5)\n    continue\n  else:\n      break\n\nprint (\"found file \"+fname0);\n\nwhile True:\n  try:\n      s3.Object('${Bucket}', fname1).load() \n  except:\n    time.sleep(5)\n    continue\n  else:\n      break\n\nprint (\"found file \"+fname1);\n\n# we can now delete the go files and move on with jobplan\ns3.Object('${Bucket}', fname0).delete() \ns3.Object('${Bucket}', fname1).delete() "}}}},"visible":true},"3":{"slot":3,"name":"Interpreter","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"Python 3"}}}},"visible":true},"4":{"slot":4,"name":"Timeout","elements":{"1":{"slot":1,"values":{"1":{"slot":1,"type":"STRING","value":"1800"}}}},"visible":true}},"expectedFailure":null,"activationStatus":"ENABLED","outputIterationConnectorIDs":[],"inputIterationConnectorIDs":[]}},"successConnectors":{"196876":{"id":196876,"sourceID":196873,"targetID":196868},"196880":{"id":196880,"sourceID":196878,"targetID":196873},"196881":{"id":196881,"sourceID":196879,"targetID":196878},"196882":{"id":196882,"sourceID":196877,"targetID":196879},"196883":{"id":196883,"sourceID":196875,"targetID":196877},"196887":{"id":196887,"sourceID":196868,"targetID":196874}},"failureConnectors":{},"unconditionalConnectors":{"196886":{"id":196886,"sourceID":196872,"targetID":196875}},"trueConnectors":{},"falseConnectors":{},"iterationConnectors":{},"noteConnectors":{},"notes":{"196869":{"id":196869,"x":-413,"y":8,"width":442,"height":205,"text":"********** IN EVENT OF WAIT TIMEOUT ****\n****Chances are the API worked fine and files just landed after time out\nFirst go to s3://bbw-staging-nestle/data_in/NESTLE_READ_API/to_process and see if the expected files exist.\n\nSecondly go to cleaning server and check the logs for the Visual Cron Job (possibilities - 1 API failed due to issues READ end, 2 - API call worked but files failed to transfer to S3 or 3 - Other issue our end)\n\nIt is important to understand, if the API worked we will be charged for the data so should use returned files if present - rerunning the whole job could result in us being charged twice if the first call actually worked.**\n\nThere are further notes on retries in sharepoint","colour":"d60000"}},"variables":{"DateForQueue":{"definition":{"name":"DateForQueue","type":"DATETIME","scope":"TASKBATCH","description":"","visibility":"PUBLIC"},"value":"2020-01-01"}},"grids":{}},"info":{"name":"Read_API EXPMORT Call","description":"Calls API for Experian Mortality ","type":"ORCHESTRATION","tag":"e8b2e044-b085-4879-9f7e-b2ee36c46533"}}